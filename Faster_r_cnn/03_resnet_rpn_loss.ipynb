{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.layers as KL\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一个stage有多个building_bolock组成\n",
    "def building_block(filters, block):\n",
    "     #控制传入参数,内部定义新函数,最后返回这个函数即可\n",
    "    if block !=0 :\n",
    "        stride = 1\n",
    "    else:\n",
    "        stride = 2\n",
    "    def f(x):\n",
    "        y = KL.Conv2D(filters, (1,1), strides=stride)(x)#只第一层改变stride\n",
    "        y = KL.BatchNormalization(axis=3)(y)#batch一般较小，chanel上做归一化\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(filters, (3,3), padding=\"same\")(y)\n",
    "        y = KL.BatchNormalization(axis=3)(y)\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        \n",
    "        y = KL.Conv2D(4*filters, (1,1))(y)\n",
    "        y = KL.BatchNormalization(axis=3)(y)\n",
    "         #分支路线，输入x和最后的y相加，shape要一样\n",
    "        if block == 0:\n",
    "            shorcut = KL.Conv2D(4*filters, (1,1), strides=stride)(x)\n",
    "            shorcut = KL.BatchNormalization(axis=3)(shorcut)\n",
    "        else:\n",
    "            shorcut = x\n",
    "        y = KL.Add()([y, shorcut])\n",
    "        y = KL.Activation(\"relu\")(y)\n",
    "        return y\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resNet_featureExtractor(inputs):\n",
    "    #进入block前的预处理\n",
    "    x = KL.Conv2D(64, (3,3), padding=\"same\")(inputs)\n",
    "    x = KL.BatchNormalization(axis=3)(x)\n",
    "    x = KL.Activation(\"relu\")(x)\n",
    "    \n",
    "    filters = 64\n",
    "    blocks = [6, 6, 6]#之前[3,6,4]\n",
    "    for i, block_num in enumerate(blocks):\n",
    "          #一个block_num为一个stage,有block_num个building_block\n",
    "        for block_id in range(block_num):\n",
    "            x = building_block(filters, block_id)(x)\n",
    "        filters *= 2#第一次扩大四倍，64*4，再*2*2=1024\n",
    "    return x#返回了featuremap          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##测试res_net\n",
    "x = KL.Input((64,64,3))\n",
    "y = resNet_featureExtractor(x)\n",
    "model = Model([x],[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature map上每个点对应k个锚框，这里是9\n",
    "def rpn_net(inputs, k):\n",
    "    #再sliding一次生成shared_map\n",
    "    shared_map = KL.Conv2D(256, (3,3), padding=\"same\")(inputs)\n",
    "    shared_map = KL.Activation(\"linear\")(shared_map)\n",
    "    #分两路全连接计算predict值和外部bbox计算loss\n",
    "    rpn_class = KL.Conv2D(2*k, (1,1))(shared_map)\n",
    "    #reshape和target一致的大小,方便计算Loss,参数分别为(batch_size,anchors,前后景概率)\n",
    "    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,2]))(rpn_class)\n",
    "    rpn_class = KL.Activation(\"linear\")(rpn_class)\n",
    "    rpn_prob = KL.Activation(\"softmax\")(rpn_class)#输出分类概率\n",
    "    \n",
    "    y = KL.Conv2D(4*k, (1,1))(shared_map)\n",
    "    y = KL.Activation(\"linear\")(y)\n",
    "    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [tf.shape(x)[0],-1,4]))(y)\n",
    "    return rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'activation_82/Identity:0' shape=(?, ?, 2) dtype=float32>,\n",
       " <tf.Tensor 'activation_83/truediv:0' shape=(?, ?, 2) dtype=float32>,\n",
       " <tf.Tensor 'lambda_2/Reshape:0' shape=(?, ?, 4) dtype=float32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##测试rpn_net\n",
    "x = KL.Input((64, 64, 3))\n",
    "fp = resNet_featureExtractor(x)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(fp, 9)\n",
    "model = Model([x],[rpn_class, rpn_prob, rpn_bbox])   ## forward，神经网络部分结束\n",
    "#model.summary()\n",
    "rpn_class, rpn_prob, rpn_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn_class_loss(rpn_match, rpn_class_logits):\n",
    "    ## rpn_match (None, 576, 1),外部输入的label（0,-1,1）\n",
    "    ## rpn_class_logits (None, 576, 2)\n",
    "    \n",
    "    rpn_match = tf.squeeze(rpn_match, -1)#压索一维则取出的是一维坐标\n",
    "    indices = tf.where(K.not_equal(rpn_match, 0))#取出不为0的label（-1,1）的位置,并变为True\n",
    "    anchor_class = K.cast(K.equal(rpn_match, 1), tf.int32)#将True转为0,1才能计算cross_entropy\n",
    "    \n",
    "    #按位置对处理过的rpn_match和rpn_logits按位置取出需要运算的部分\n",
    "    rpn_class_logits = tf.gather_nd(rpn_class_logits, indices)     ### prediction\n",
    "    anchor_class = tf.gather_nd(anchor_class, indices)   ### target\n",
    "    \n",
    "    #from_logits=True是否是softmax得到的prediction\n",
    "    loss = K.sparse_categorical_crossentropy(target=anchor_class, output=rpn_class_logits, from_logits=True)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))#异常处理,若没有找到有效label的位置\n",
    "    return loss\n",
    "\n",
    "def batch_back(x,counts,num_rows):\n",
    "    outputs = []\n",
    "    for i in range(num_rows):\n",
    "        outputs.append(x[i,:counts[i]])\n",
    "    return tf.concat(outputs,axis=0)\n",
    "\n",
    "def rpn_bbox_loss(target_bbox, rpn_match, rpn_bbox):\n",
    "    rpn_match = tf.squeeze(rpn_match, -1)\n",
    "    indices = tf.where(K.equal(rpn_match, 1))\n",
    "    rpn_bbox = tf.gather_nd(rpn_bbox, indices)\n",
    "    \n",
    "    ###取target_bbox,\n",
    "    #在每个batch（None纬）里面找前n个计算,每个batch的n不同\n",
    "    batch_counts = K.sum(K.cast(K.equal(rpn_match, 1), tf.int32), axis=1)\n",
    "    #batch_counts = [3,5,15,20...],最后一个参数为batch_size,即rows\n",
    "    target_bbox = batch_back(target_bbox, batch_counts, 20)\n",
    "    \n",
    "    #L1loss,L2loss会关注diff值差较大的去优化,我们关注近似的锚框\n",
    "    diff = K.abs(target_bbox - rpn_bbox)\n",
    "    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n",
    "    #小于1的用平方,大于1的用直线,达到分段目的,不至于越大越敏感\n",
    "    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n",
    "    loss = K.switch(tf.size(loss) > 0 , K.mean(loss), tf.constant(0.0))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = KL.Input(shape=[64,64,3], dtype=tf.float32)\n",
    "#None目标的个数,之和为定值,可变不定死\n",
    "input_bboxes = KL.Input(shape=[None,4], dtype=tf.float32)#输入的真实的bboxes\n",
    "input_class_ids = KL.Input(shape=[None],dtype=tf.int32)#每一种目标的形状,三角长方等,后面用\n",
    "#下面None锚框的个数,input_rpn_match两种loss都用来取indics\n",
    "input_rpn_match = KL.Input(shape=[None, 1], dtype=tf.int32)#-1,0,1\n",
    "input_rpn_bbox = KL.Input(shape=[None, 4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_map = resNet_featureExtractor(input_image)\n",
    "rpn_class, rpn_prob, rpn_bbox = rpn_net(feature_map, 9)\n",
    "\n",
    "#Lambda函数添加层,函数可外部实现,该函数仅接受一个变量，即上一层的输出\n",
    "\n",
    "#分类loss\n",
    "loss_rpn_match = KL.Lambda(lambda x: rpn_class_loss(*x), name=\"loss_rpn_match\")([input_rpn_match, rpn_class])\n",
    "#回归loss\n",
    "loss_rpn_bbox = KL.Lambda(lambda x: rpn_bbox_loss(*x), name=\"loss_rpn_bbox\")([input_rpn_bbox, input_rpn_match, rpn_bbox])\n",
    "\n",
    "model = Model([input_image, input_bboxes, input_class_ids, input_rpn_match, input_rpn_bbox],\n",
    "              [rpn_class, rpn_prob, rpn_bbox, loss_rpn_match, loss_rpn_bbox])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "loss_lay1 = model.get_layer(\"loss_rpn_match\").output\n",
    "loss_lay2 = model.get_layer(\"loss_rpn_bbox\").output\n",
    "\n",
    "model.add_loss(tf.reduce_mean(loss_lay1))\n",
    "model.add_loss(tf.reduce_mean(loss_lay2))\n",
    "#都加进层了所以output都设为None,不用来算梯度\n",
    "model.compile(loss=[None]*len(model.output), optimizer=keras.optimizers.SGD(lr=0.00005, momentum=0.9))\n",
    "\n",
    "#加入展示\n",
    "model.metrics_names.append(\"loss_rpn_match\")\n",
    "model.metrics_tensors.append(tf.reduce_mean(loss_lay1, keepdims=True))\n",
    "\n",
    "model.metrics_names.append(\"loss_rpn_bbox\")\n",
    "model.metrics_tensors.append(tf.reduce_mean(loss_lay2, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import shapeData as dataSet\n",
    "from config import Config\n",
    "\n",
    "config = Config()\n",
    "dataset = dataSet([64,64], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_Gen(dataset, num_batch, batch_size, config):\n",
    "    for _ in range(num_batch):\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        class_ids = []\n",
    "        rpn_matchs = []\n",
    "        rpn_bboxes = []\n",
    "        for i in range(batch_size):\n",
    "            image, bbox, class_id, rpn_match, rpn_bbox, _ = data = dataset.load_data()\n",
    "            pad_num = config.max_gt_obj - bbox.shape[0]\n",
    "            pad_box = np.zeros((pad_num, 4))\n",
    "            pad_ids = np.zeros((pad_num, 1))\n",
    "            bbox = np.concatenate([bbox, pad_box], axis=0)\n",
    "            class_id = np.concatenate([class_id, pad_ids], axis=0)\n",
    "        \n",
    "            images.append(image)\n",
    "            bboxes.append(bbox)\n",
    "            class_ids.append(class_id)\n",
    "            rpn_matchs.append(rpn_match)\n",
    "            rpn_bboxes.append(rpn_bbox)\n",
    "        images = np.concatenate(images, 0).reshape(batch_size, config.image_size[0],config.image_size[1] , 3)\n",
    "        bboxes = np.concatenate(bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        class_ids = np.concatenate(class_ids, 0).reshape(batch_size, -1 )\n",
    "        rpn_matchs = np.concatenate(rpn_matchs, 0).reshape(batch_size, -1 , 1)\n",
    "        rpn_bboxes = np.concatenate(rpn_bboxes, 0).reshape(batch_size, -1 , 4)\n",
    "        yield [images, bboxes, class_ids, rpn_matchs, rpn_bboxes],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset,num_batch,batch_size要和上面batch_back函数rows一样\n",
    "dataGen = data_Gen(dataset, 35000, 20, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "#his = model.fit_generator(dataGen, steps_per_epoch=20, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.save_weights(\"model_material.h5\")\n",
    "model.load_weights(\"model_material.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    "    \n",
    "def boxes_clip(boxes, window):\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n",
    "    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    cliped = tf.concat([y1, x1, y2, x2], axis=1)\n",
    "    cliped.set_shape((cliped.shape[0], 4))\n",
    "    return cliped\n",
    "    \n",
    "def batch_slice(inputs, graph_fn, batch_size):\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "    output = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]\n",
    "        output_slice = graph_fn(*inputs_slice)\n",
    "        if not isinstance(output_slice, (list, tuple)):\n",
    "            output_slice = [output_slice]\n",
    "        output.append(output_slice)\n",
    "    output = list(zip(*output))\n",
    "    result = [tf.stack(o, axis=0) for o in output]\n",
    "    if len(result)==1:\n",
    "        result = result[0]\n",
    "    return result\n",
    "\n",
    "import keras.engine as KE\n",
    "\n",
    "class proposal(KE.Layer):\n",
    "    def __init__(self, proposal_count, nms_thresh, anchors, batch_size, config=None, **kwargs):\n",
    "        super(proposal, self).__init__(**kwargs)\n",
    "        self.proposal_count = proposal_count\n",
    "        self.anchors = anchors\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.batch_size = batch_size\n",
    "        self.config = config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        probs = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, (1, 1, 4))\n",
    "        prenms_num = min(100, self.anchors.shape[0])\n",
    "        idxs = tf.nn.top_k(probs, prenms_num).indices\n",
    "        \n",
    "        probs = batch_slice([probs, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        deltas = batch_slice([deltas, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        anchors = batch_slice([idxs], lambda x:tf.gather(self.anchors,x), self.batch_size)\n",
    "        refined_boxes = batch_slice([anchors, deltas], lambda x,y:anchor_refinement(x,y), self.batch_size)\n",
    "        H,W = self.config.image_size[:2]\n",
    "        windows = np.array([0,0,H,W]).astype(np.float32)\n",
    "        cliped_boxes = batch_slice([refined_boxes], lambda x:boxes_clip(x, windows), self.batch_size)\n",
    "        normalized_boxes = cliped_boxes / np.array([H,W,H,W])\n",
    "        def nms(normalized_boxes, scores):\n",
    "            idxs_ = tf.image.non_max_suppression(normalized_boxes, scores, self.proposal_count, self.nms_thresh)\n",
    "            box = tf.gather(normalized_boxes, idxs_)\n",
    "            pad_num = tf.maximum(self.proposal_count - tf.shape(normalized_boxes)[0],0)\n",
    "            box = tf.pad(box, [(0,pad_num),(0,0)])\n",
    "            return box\n",
    "        proposal_ = batch_slice([normalized_boxes, probs], nms, self.batch_size)\n",
    "        return proposal_\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#和算rpn_target是相反的操作,deltas为anchor偏移量\n",
    "def anchor_refinement(boxes, deltas):\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    h = boxes[:, 2] - boxes[:, 0]\n",
    "    w = boxes[:, 3] - boxes[:, 1]\n",
    "    center_y = boxes[:, 0] + h / 2\n",
    "    center_x = boxes[:, 1] + w / 2\n",
    "\n",
    "    center_y += deltas[:, 0] * h\n",
    "    center_x += deltas[:, 1] * w\n",
    "    h *= tf.exp(deltas[:, 2])\n",
    "    w *= tf.exp(deltas[:, 3])\n",
    "    \n",
    "    y1 = center_y - h / 2\n",
    "    x1 = center_x - w / 2\n",
    "    y2 = center_y + h / 2\n",
    "    x2 = center_x + w / 2\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=1)\n",
    "    return boxes\n",
    " \n",
    "#把anchor限制在一个范围内,不超过featuremap的大小   \n",
    "def boxes_clip(boxes, window):\n",
    "    wy1, wx1, wy2, wx2 = tf.split(window, 4)#窗4个坐标\n",
    "    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)#box4个坐标\n",
    "    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n",
    "    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n",
    "    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n",
    "    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n",
    "    cliped = tf.concat([y1, x1, y2, x2], axis=1)\n",
    "    cliped.set_shape((cliped.shape[0], 4))\n",
    "    return cliped\n",
    "\n",
    "#将batch切片,拓展到一个batch去运算Fn函数,\n",
    "#类似batch_pack,不知道每个batch有多少个正锚框,用[15,20,3]\n",
    "def batch_slice(inputs, graph_fn, batch_size):\n",
    "    if not isinstance(inputs, list):\n",
    "        inputs = [inputs]\n",
    "    output = []\n",
    "    for i in range(batch_size):\n",
    "        inputs_slice = [x[i] for x in inputs]#取出一个batch\n",
    "        output_slice = graph_fn(*inputs_slice)#对其用fn得到output\n",
    "        if not isinstance(output_slice, (list, tuple)):\n",
    "            output_slice = [output_slice]\n",
    "        output.append(output_slice)#output加进一个数组里\n",
    "    output = list(zip(*output))#打包output\n",
    "    result = [tf.stack(o, axis=0) for o in output]\n",
    "    if len(result)==1:\n",
    "        result = result[0]\n",
    "    return result\n",
    "\n",
    "import keras.engine as KE\n",
    "\n",
    "class proposal(KE.Layer):\n",
    "    #config外部配置参数,**kwargs放置一些可变参数\n",
    "    def __init__(self, proposal_count, nms_thresh, anchors, batch_size, config=None, **kwargs):\n",
    "        super(proposal, self).__init__(**kwargs)\n",
    "        self.proposal_count = proposal_count\n",
    "        self.anchors = anchors\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.batch_size = batch_size\n",
    "        self.config = config\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        probs = inputs[0][:, :, 1]\n",
    "        deltas = inputs[1]\n",
    "        deltas = deltas * np.reshape(self.config.RPN_BBOX_STD_DEV, (1, 1, 4))\n",
    "        prenms_num = min(100, self.anchors.shape[0])#万一锚框不够做个判断,取100个\n",
    "        idxs = tf.nn.top_k(probs, prenms_num).indices#前num个编号\n",
    "        \n",
    "        #1、probs = 取出rpn输出得分最高的锚框(rpn_class里的)\n",
    "        #2、取出得分最高的修正量delta \n",
    "        #3、同样取出这样anchors然后做修正\n",
    "        #4、clip一下防止跑出窗口搞到外面去\n",
    "        probs = batch_slice([probs, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        deltas = batch_slice([deltas, idxs], lambda x,y:tf.gather(x, y), self.batch_size)\n",
    "        anchors = batch_slice([idxs], lambda x:tf.gather(self.anchors,x), self.batch_size)\n",
    "        refined_boxes = batch_slice([anchors, deltas], lambda x,y:anchor_refinement(x,y), self.batch_size)\n",
    "        H,W = self.config.image_size[:2]#3为channel\n",
    "        \n",
    "        windows = np.array([0,0,H,W]).astype(np.float32)\n",
    "        cliped_boxes = batch_slice([refined_boxes], lambda x:boxes_clip(x, windows), self.batch_size)\n",
    "        normalized_boxes = cliped_boxes / np.array([H,W,H,W])#都用0-1防止映射到后续不同大小的map\n",
    "        \n",
    "        def nms(normalized_boxes, scores):\n",
    "            idxs_ = tf.image.non_max_suppression(normalized_boxes, scores, self.proposal_count, self.nms_thresh)\n",
    "            box = tf.gather(normalized_boxes, idxs_)\n",
    "            pad_num = tf.maximum(self.proposal_count - tf.shape(normalized_boxes)[0],0)\n",
    "            box = tf.pad(box, [(0,pad_num),(0,0)])\n",
    "            return box\n",
    "        proposal_ = batch_slice([normalized_boxes, probs], nms, self.batch_size)\n",
    "        return proposal_\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.proposal_count, 4)\n",
    "    \n",
    "    #def build: weights,不需要训练参数只是组合逻辑关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataGen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0973c0ad948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataGen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataGen' is not defined"
     ]
    }
   ],
   "source": [
    "test_data = next(dataGen)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = test_data[0]\n",
    "bboxes = test_data[1]\n",
    "class_ids = test_data[2]\n",
    "rpn_matchs = test_data[3]\n",
    "rpn_bboxes = test_data[4]\n",
    "\n",
    "\n",
    "rpn_class, rpn_prob, rpn_bbox, _, _ = \\\n",
    "                model.predict([images, bboxes, class_ids, rpn_matchs, rpn_bboxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpn_class = tf.convert_to_tensor(rpn_class)\n",
    "rpn_prob = tf.convert_to_tensor(rpn_prob)\n",
    "rpn_bbox = tf.convert_to_tensor(rpn_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "anchors = utils.anchor_gen([8,8], ratios=config.ratios, scales=config.scales, rpn_stride=config.rpn_stride, \n",
    "                           anchor_stride = config.anchor_stride)\n",
    "\n",
    "\n",
    "proposals = proposal(proposal_count=16, nms_thresh=0.7, anchors=anchors, batch_size=20, config=config)([rpn_prob, rpn_bbox])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "proposals_ = sess.run(proposals) * 64#归一下除了长宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#images.shape = (20，64，64，3)一个batch有20个image\n",
    "ix = random.sample(range(20), 1)[0]#20里取一个image\n",
    "proposal_ = proposals_[ix]#proposal和取出的下标对应\n",
    "img = images[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)\n",
    "axs = plt.gca()\n",
    "\n",
    "#proposal_.shape = （16，4）\n",
    "for i in range(proposal_.shape[0]):\n",
    "    box = proposal_[i]\n",
    "    rec = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], facecolor='none', edgecolor='r')\n",
    "    axs.add_patch(rec)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
